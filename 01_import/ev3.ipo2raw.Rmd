---
title: "Inlezen IPO Signaleringskaart Externe Veiligheid"
author: "Gerrit Versteeg"
date: "14/02/2024"
output: pdf_document
---

## Introductie
Dit script rapporteert het inlezen van geografische gegevens rond de externe veiligheid. Hierbinnen vallen:

* EV Quickscans  
* Risico bronnen / Aandachtsgebieden  
* Kwestbare objecten  
* Ruimtelijke plannen  


## Ruwe WFS-layers aandachtsgebieden

* Bron: https://nl.evsignaleringskaart.nl  
* URL: https://nl.evsignaleringskaart.nl/geoserver/quickscans/wfs  
* Format: ZIP-file  
* Periode: 2023  
* Gebied: Nederland  
* Datalake: ruwe_data/IPO_InterProvOverleg/ev_signaleringskaart/aandachtsgebieden  

## Ruwe WFS-layers kwetsbare objecten

* Bron: https://nl.evsignaleringskaart.nl  
* URL: https://nl.evsignaleringskaart.nl/geoserver/kwetsbaarheid_objecten/wfs  
* Format: ZIP-file  
* Periode: 2023  
* Gebied: Nederland  
* Datalake: ruwe_data/IPO_InterProvOverleg/ev_signaleringskaart/kwetsbare_objecten  


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## -------------------------------------------------------------------------- #
## ----------- housekeeping ------------------------------------------------- #
## -------------------------------------------------------------------------- #
## loading libraries -------------------------------------------------------- #
library(jsonlite)
library(tidyverse)
library(sf)
library(RCurl)
library(XML)
# library(ows4R)

##--------------------------------------------------------------------------- #
## sourcing relevant functions ---------------------------------------------- #
##--------------------------------------------------------------------------- #
source("../functions/analyzeWFS.R")

## Folders and paths -------------------------------------------------------- #
dir_parm <- "../parameters/"
## dir_base <- Sys.getenv("POS_DATALAKE")
dir_base <- "~/link_datalake/Weert/"

dir_raw <- paste0(dir_base, "ruwe_data/")
dir_cln <- paste0(dir_base, "schone_data/")
dir_raw_ipo <- paste0(dir_raw, "IPO_InterProvOverleg/ev_signaleringskaart/")
dir_raw_ag <- paste0(dir_raw_ipo, "aandachtsgebieden")
dir_raw_kgl <- paste0(dir_raw_ipo, "kwetsbare_objecten")
dir_raw_gg <- paste0(dir_raw_ipo, "hulplagen")
dir_raw_geo <- paste0(dir_raw, "GeoBasis/")

fname_geo_gem <- "/gemeenten/gemeenten2019.shp"
fpath_geo_gem <- paste0(dir_raw_geo, fname_geo_gem)

fname_parm <- "ipo_ev.json"
fpath_parm <- paste0(dir_parm, fname_parm)

fname_raw_capqs <- "ipo_cap_qs.xml"
fpath_raw_capqs <- paste0(dir_raw_ipo, fname_raw_capqs)
fname_raw_capkg <- "ipo_cap_kg.xml"
fpath_raw_capkg <- paste0(dir_raw_ipo, fname_raw_capkg)
fname_raw_ag <- "ipo_ag.zip"
fpath_raw_ag <- paste0(dir_raw_ag, "/", fname_raw_ag)
fname_raw_kg <- "ipo_kg.zip"
fpath_raw_kg <- paste0(dir_raw_kgl, "/", fname_raw_kg)

fname_tbl_ag <- "feature_table_ag.rds"
fpath_tbl_ag <- paste0(dir_raw_ag, "/", fname_tbl_ag)
fname_tbl_kgl <- "feature_table_kgl.rds"
fpath_tbl_kgl <- paste0(dir_raw_kgl, "/", fname_tbl_kgl)

```


## Importeren

### Inlezen ruwe data

De bron is de ev-signaleringskaart van het IPO, waarin bestanden beschikbaar zijn o.b.v. een specfieke URL. Die URL's zijn vastgelegd in een JSON-bestand (ipo_ev.json) in de parameters folder.


```{r read, echo=FALSE, warning=FALSE}
## -------------------------------------------------------------------------- #
## ----------- inlezen DATA vanuit EV-SIGNALERINGSKAART IPO ----------------- #
## -------------------------------------------------------------------------- #
## ----------- data retrieval ----------------------------------------------- #
## 1. URL's inladen vanuit parameter-file ipo_ev.json                         #
## -------------------------------------------------------------------------- #
ipo_codes <- read_lines(fpath_parm) %>% 
  fromJSON()
ipo_codes <- ipo_codes$ipodata
## Load secrets for data source --------------------------------------------- #
opts = curlOptions(userpwd = paste0(Sys.getenv("IPO_user"),
                                    ":", Sys.getenv("IPO_password")))

## -------------------------------------------------------------------------- #
## -- DEEL 0: INLADEN GEMEENTEGRENZEN --------------------------------------- #
## -------------------------------------------------------------------------- #
## -------------------------------------------------------------------------- #
## Data inladen rond gemeentegrens om een bounding box te maken ------------- #
##  voor de gemente Den Haag, die we kunnen gebruiken bij het filteren ------ #
##  van data uit de ev-signaleringskaart ------------------------------------ #
##  We ronden af , zodat het filteren sneller kan verlopen (lijkt het) ------ #
## -------------------------------------------------------------------------- #
sf_gem <- read_sf(fpath_geo_gem) %>% 
  filter(gemeentena == "Weert")
x <- st_bbox(sf_gem)
x[["xmin"]] <- round(x[["xmin"]], 0)
x[["ymin"]] <- round(x[["ymin"]], 0)
x[["xmax"]] <- round(x[["xmax"]]+1, 0)
x[["ymax"]] <- round(x[["ymax"]]+1, 0)
bb_wrt <- paste(as.integer(x), collapse = ",")

## -------------------------------------------------------------------------- #
## -- DEEL 1: KLAARZETTEN URL REQUEST VARIANTEN IPO ------------------------- #
## -------------------------------------------------------------------------- #
req_type <- "request=GetFeature"
req_serv <- "&service=wfs"
req_name <- "&typeName="
req_form <- "&outputFormat=SHAPE-ZIP"
req_vers <- "&version=2.0.0"
req_cnt <- "&count=25000"
req_start <- "&startindex=1"
# gem_naam <- "='s-Gravenhage'"
gem_naam <- "=Weert"
req_filt <- paste0("&cql_filter=gemnaam", gem_naam)
req_bbox <- paste0("&BBOX=",bb_wrt)

## -------------------------------------------------------------------------- #
## -- DEEL 1: INLADEN AANDACHTSGEBIEDEN ------------------------------------- #
## -------------------------------------------------------------------------- #
## -------------------------------------------------------------------------- #
## Data inladen Capabilities voor gedeelte "quickscans" vanuit IPO ---------- #
##  Hierin zitten de risicobronnen en aandachtsgebieden ih.k.v. de Ow ------- #
## -------------------------------------------------------------------------- #
url_base <- ipo_codes$url_base[ipo_codes$item == "quickscans"]
url_hits <- ipo_codes$url_hits[ipo_codes$item == "quickscans"]
url_cap <- ipo_codes$url_gcap[ipo_codes$item == "quickscans"]
error_download <- download.file(url_cap, destfile = fpath_raw_capqs)
stopifnot(error_download == 0) 

## -------------------------------------------------------------------------- # 
## --- xml_in --------- OPZETTEN DATAFAME MET BESCHIKBARE FEATURETYPES ------ #
## -------------------------------------------------------------------------- # 
## Bij XML altijd bestand eerst als binary file in geheugen lezen en dan 
## deze file uit geheugen gaan parsen als XML (xmlParse / read_xml)
## 1 - inlezen bestand als binary file in geheugen
## 2 - inlezen XML-bestand voor gebruik met package XML
## 3 - selecteren van de FeatureTypeList
## -------------------------------------------------------------------------- # 
xml_in <- read_file(fpath_raw_capqs)
##
## @@@@@
## even: bezig om onderstaande code in een separate functie te zetten !
## even: nog kijken hoe we de hits erbij halen..... misschien via base-url in de xml?
## even: kunnen we bij de API UID/PWD of geven we die mee in function-call?
## x <- analyzeWFS(xml_in)

##
data <- xmlParse(xml_in)
lst_getcap <- xmlToList(data)
lst_ftl <- lst_getcap$FeatureTypeList

## start de bouw v.h. dataframe voor beschikbare FeatureTypes
df_ftl_ag <- data.frame(name = character(0),
                 title = character(0),
                 abstract = character(0),
                 keyword_1 = character(0),
                 keyword_2 = character(0),
                 def_crs = character(0),
                 bbox_lc = character(0),
                 bbox_uc = character(0),
                 nr_in_NL = integer(0),
                 nr_in_DH = integer(0),
                 stringsAsFactors = FALSE)
index <- c(1:length(lst_ftl))
curfeat <- NA

## loop voor het vullen van het dataframe voor beschikbare FeatureTypes
for (i in seq_along(index)) {
  df_ftl_ag[i,] <- NA
  curfeat <- lst_ftl[i]
  df_ftl_ag$name[i] <- curfeat$FeatureType$Name
  df_ftl_ag$title[i] <- curfeat$FeatureType$Title
  df_ftl_ag$abstract[i] <- ifelse(is.null(curfeat$FeatureType$Abstract),"",
                               curfeat$FeatureType$Abstract)
  keywords <- unlist(curfeat$FeatureType$Keywords)
  df_ftl_ag$keyword_1[i] <- keywords[1]
  df_ftl_ag$keyword_2[i] <- keywords[2]
  df_ftl_ag$def_crs[i] <- curfeat$FeatureType$DefaultCRS
  df_ftl_ag$bbox_lc[i] <- curfeat$FeatureType$WGS84BoundingBox$LowerCorner
  df_ftl_ag$bbox_uc[i] <- curfeat$FeatureType$WGS84BoundingBox$UpperCorner
  url_hits_NL <- str_replace(url_hits, "typeName=",
                        paste0("typeName=",df_ftl_ag$name[i]))
  xml_hits_NL <- getURL(url_hits_NL, .opts=opts)
  xml_data <- xmlParse(xml_hits_NL)
  lst_hits <- xmlToList(xml_data)
  df_ftl_ag$nr_in_NL[i] <- as.numeric(lst_hits[["numberMatched"]])
  url_hits_DH <- paste0(url_hits_NL, req_bbox)
  xml_hits_DH <- getURL(url_hits_DH, .opts=opts)
  xml_data <- xmlParse(xml_hits_DH)
  lst_hits <- xmlToList(xml_data)
  df_ftl_ag$nr_in_DH[i] <- as.numeric(lst_hits[["numberMatched"]])
}

# df_ftl_ag <- x  ## temporary while developing separate function for above code
print(df_ftl_ag)
write_rds(df_ftl_ag, fpath_tbl_ag)

## -------------------------------------------------------------------------- #
## Data inladen (aandachtsgebieden vanuit IPO) ------------------------------ #
## -------------------------------------------------------------------------- #
url_init <- ipo_codes$url_feat[ipo_codes$item == "quickscans"]
for (i in seq_along(df_ftl_ag$name)) {
  url_ag <- str_replace(url_init, "typeName=",
                        paste0("typeName=", df_ftl_ag$name[i]))
  url_ag_DH <- paste0(url_ag, req_bbox)
  writeBin(getBinaryURL(url_ag_DH, .opts=opts), fpath_raw_ag)
  unzip(fpath_raw_ag, exdir = dir_raw_ag)
}
file.remove(fpath_raw_ag)

## -------------------------------------------------------------------------- #
## -- DEEL 2: INLADEN KWETSBARE OBJECTEN ------------------------------------ #
## -------------------------------------------------------------------------- #
## Data inladen Capabilities voor gedeelte "kwetsbare_objecten" vanuit IPO -- #
##  Hierin zitten de kwetsbare objecten en hun locaties --------------------- #
## -------------------------------------------------------------------------- #
url_base <- ipo_codes$url_base[ipo_codes$item == "kwetsbareobjecten"]
url_hits <- ipo_codes$url_hits[ipo_codes$item == "kwetsbareobjecten"]
url_cap <- ipo_codes$url_gcap[ipo_codes$item == "kwetsbareobjecten"]
error_download <- download.file(url_cap, destfile = fpath_raw_capkg)
stopifnot(error_download == 0) 

## -------------------------------------------------------------------------- # 
## --- xml_in --------- OPZETTEN DATAFAME MET BESCHIKBARE FEATURETYPES ------ #
## -------------------------------------------------------------------------- # 
## Bij XML altijd bestand eerst als binary file in geheugen lezen en dan 
## deze file uit geheugen gaan parsen als XML (xmlParse / read_xml)
## 1 - inlezen bestand als binary file in geheugen
## 2 - inlezen XML-bestand voor gebruik met package XML
## 3 - selecteren van de FeatureTypeList
## -------------------------------------------------------------------------- # 
xml_in <- read_file(fpath_raw_capkg)
data <- xmlParse(xml_in)
lst_getcap <- xmlToList(data)
lst_ftl <- lst_getcap$FeatureTypeList

## start de bouw v.h. dataframe voor beschikbare FeatureTypes
df_ftl_kgl <- data.frame(name = character(0),
                 title = character(0),
                 abstract = character(0),
                 keyword_1 = character(0),
                 keyword_2 = character(0),
                 def_crs = character(0),
                 bbox_lc = character(0),
                 bbox_uc = character(0),
                 nr_in_NL = integer(0),
                 nr_in_DH = integer(0),
                 stringsAsFactors = FALSE)
index <- c(1:length(lst_ftl))
curfeat <- NA

## loop voor het vullen van het dataframe voor beschikbare FeatureTypes
for (i in seq_along(index)) {
  df_ftl_kgl[i,] <- NA
  curfeat <- lst_ftl[i]
  df_ftl_kgl$name[i] <- curfeat$FeatureType$Name
  df_ftl_kgl$title[i] <- curfeat$FeatureType$Title
  df_ftl_kgl$abstract[i] <- ifelse(is.null(curfeat$FeatureType$Abstract),"",
                               curfeat$FeatureType$Abstract)
  keywords <- unlist(curfeat$FeatureType$Keywords)
  df_ftl_kgl$keyword_1[i] <- keywords[1]
  df_ftl_kgl$keyword_2[i] <- keywords[2]
  df_ftl_kgl$def_crs[i] <- curfeat$FeatureType$DefaultCRS
  df_ftl_kgl$bbox_lc[i] <- curfeat$FeatureType$WGS84BoundingBox$LowerCorner
  df_ftl_kgl$bbox_uc[i] <- curfeat$FeatureType$WGS84BoundingBox$UpperCorner
  url_hits_NL <- str_replace(url_hits, "typeName=",
                        paste0("typeName=",df_ftl_kgl$name[i]))
  xml_hits_NL <- getURL(url_hits_NL, .opts=opts)
  xml_data <- xmlParse(xml_hits_NL)
  lst_hits <- xmlToList(xml_data)
  df_ftl_kgl$nr_in_NL[i] <- as.numeric(lst_hits[["numberMatched"]])
  url_hits_DH <- paste0(url_hits_NL, req_bbox)
  xml_hits_DH <- getURL(url_hits_DH, .opts=opts)
  xml_data <- xmlParse(xml_hits_DH)
  lst_hits <- xmlToList(xml_data)
  df_ftl_kgl$nr_in_DH[i] <- as.numeric(lst_hits[["numberMatched"]])
}

print(df_ftl_kgl)
write_rds(df_ftl_kgl, fpath_tbl_kgl)

## -------------------------------------------------------------------------- #
## Data inladen (kwetsbare objecten vanuit IPO) ----------------------------- #
## -------------------------------------------------------------------------- #
url_init <- ipo_codes$url_feat[ipo_codes$item == "kwetsbareobjecten"]
max_pg <- 25000
req_count <- paste0("&count=", max_pg)

for (i in seq_along(df_ftl_kgl$name)) {
  nm_feat <- df_ftl_kgl$name[i]
  nr_feat <- df_ftl_kgl$nr_in_DH[i]
  url_kg <- str_replace(url_init, "typeName=",
                        paste0("typeName=", nm_feat))
  nm_file <- paste0(str_split(nm_feat, ":")[[1]][2], ".shp")
  nm_path <- paste0(dir_raw_kgl, "/", nm_file)
  if (nr_feat < max_pg) {
    url_kg_DH <- paste0(url_kg, req_bbox)
    writeBin(getBinaryURL(url_kg_DH, .opts=opts), fpath_raw_kg)
    unzip(fpath_raw_kg, exdir = dir_raw_kgl)
  } else {
    nr_pgs <- round(nr_feat/max_pg, digits = 0) + 1
    vct_pgs <- seq(from = 1, to = nr_feat, by = max_pg)
    for (j in seq_along(vct_pgs)) {
      req_start <- paste0("&startindex=", vct_pgs[j])
      url_kg_DH <- paste0(url_kg, req_bbox, req_start, req_count)
      writeBin(getBinaryURL(url_kg_DH, .opts=opts), fpath_raw_kg)
      if (j == 1) {
        unzip(fpath_raw_kg, exdir = dir_raw_kgl)
        sf_base <- read_sf(nm_path)
      } else {
        unzip(fpath_raw_kg, exdir = dir_raw_kgl)
        sf_add <- read_sf(nm_path)
        sf_base <- bind_rows(sf_base, sf_add)
      }
      print(nrow(sf_base))
    }
    write_sf(sf_base, nm_path)
  }
  file.remove(fpath_raw_kg)
}
rm(sf_1, sf_add)

# WFS_url <- paste0("http://geodata.nationaalgeoregister.nl/natura2000/wfs?",
#                   "&service=wfs&version=2.0.0&request=GetFeature",
#                   "&typeName=natura2000:natura2000",
#                   "&outputFormat=application/json")

## test connectie met file ------------------- ##
# bin <- getBinaryURL(url_kg, .opts=opts)
# con <- file(fpath_raw_kg, open = "wb")
# writeBin(bin, con)
# close(con)
## ------------------------------------------- ##


```

